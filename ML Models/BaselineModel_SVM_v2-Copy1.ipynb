{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "solid-mexican",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n",
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "%autosave 60\n",
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import cross_validate\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import *\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rolled-better",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_repeat_removed_deepmag.npy\n"
     ]
    }
   ],
   "source": [
    "FEATURE_TYPE = 'deepmag' #['raw', 'deepmag']\n",
    "\n",
    "if FEATURE_TYPE == 'raw':\n",
    "    DATA_DIR = \"C:/Wasif/PD Motor Feature Extraction/TASK2_FEATURES_04_21/\"\n",
    "    X_file = \"x_repeat_removed_raw_pixels.npy\"\n",
    "    y_file = \"y_repeat_removed_raw_pixels.npy\"\n",
    "    X_index_file = \"index_repeat_removed.pickle\"\n",
    "\n",
    "elif FEATURE_TYPE == 'deepmag':\n",
    "    DATA_DIR = \"E:/Wasif/PDMotorFeatureExtraction/Task2_features_deepMAG/\"\n",
    "    X_file = \"x_repeat_removed_deepmag.npy\"\n",
    "    y_file = \"y_repeat_removed_deepmag.npy\"\n",
    "    X_index_file = \"index_repeat_removed.pickle\"\n",
    "\n",
    "SEED = 1234\n",
    "TRAIN_TEST_SPLIT = [0.80, 0.20]\n",
    "TRAIN_TEST_DEV_SPLIT = [0.70, 0.15, 0.15]\n",
    "NUM_FOLDS = 10\n",
    "np.random.seed(seed=SEED)\n",
    "IMG_HEIGHT = 492\n",
    "IMG_WIDTH = 492\n",
    "\n",
    "print(X_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "connected-christian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(DATA_DIR):\n",
    "    X = np.load(DATA_DIR+X_file)\n",
    "    #For now, only considering the frequency features\n",
    "    X = X[:,(IMG_HEIGHT*IMG_WIDTH):]\n",
    "    \n",
    "    y = np.load(DATA_DIR+y_file)\n",
    "    \n",
    "    with open(DATA_DIR+X_index_file, 'rb') as handle:\n",
    "        X_index = pickle.load(handle)  \n",
    "    \n",
    "    return (X, y, X_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "occasional-repeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMOTE_oversample(X,y):\n",
    "    oversample = SMOTE()\n",
    "    X, y = oversample.fit_resample(X, y)\n",
    "    return (X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "disciplinary-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_property(X, y):\n",
    "    positives = np.sum(y==1.0)\n",
    "    negatives = np.sum(y==0.0)\n",
    "    print(positives, negatives)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "silent-cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, y_train, model):\n",
    "    (X,y) = SMOTE_oversample(X_train,y_train)\n",
    "    #(X, y) = (X_train, y_train)\n",
    "    clf = make_pipeline(StandardScaler(), model)\n",
    "    clf.fit(X, y)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "improved-visitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y, pred_y):\n",
    "    performance = {}\n",
    "    performance['keys'] = ['accuracy', 'auc-roc', 'f1', 'precision', 'recall', 'balanced_accuracy']\n",
    "    performance['accuracy'] = accuracy_score(y, pred_y)\n",
    "    performance['auc-roc'] = roc_auc_score(y, pred_y)\n",
    "    performance['f1'] = f1_score(y, pred_y)\n",
    "    performance['precision'] = precision_score(y, pred_y)\n",
    "    performance['recall'] = recall_score(y, pred_y)\n",
    "    performance['balanced_accuracy'] = balanced_accuracy_score(y, pred_y)\n",
    "    \n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "special-april",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_CV(model, X, y, X_index, k):\n",
    "    #k iterations\n",
    "    #Split into k fold, (k-1) = train, last = test\n",
    "    #Evaluate on test\n",
    "    #Report average\n",
    "    performance = {}\n",
    "    performance['keys'] = ['accuracy', 'auc-roc', 'f1', 'precision', 'recall', 'balanced_accuracy']\n",
    "    performance['accuracy'] = 0.0\n",
    "    performance['auc-roc'] = 0.0\n",
    "    performance['f1'] = 0.0\n",
    "    performance['precision'] = 0.0\n",
    "    performance['recall'] = 0.0\n",
    "    performance['balanced_accuracy'] = 0.0\n",
    "    \n",
    "    N = X.shape[0]\n",
    "    samples_per_fold = (int)(N/k)\n",
    "    \n",
    "    X_folds = []\n",
    "    y_folds = []\n",
    "    X_index_folds = []\n",
    "    \n",
    "    shuffled_indices =np.arange(0,N) \n",
    "    np.random.shuffle(shuffled_indices)\n",
    "    \n",
    "    for fold_no in range(0,k):\n",
    "        #fold_no set is the test set\n",
    "        if fold_no==(k-1):\n",
    "            test_indices = shuffled_indices[(samples_per_fold*fold_no): N]\n",
    "        else:\n",
    "            test_indices = shuffled_indices[(samples_per_fold*fold_no): (samples_per_fold*(fold_no+1))]\n",
    "        \n",
    "        train_indices = [i for i in range(0,N) if i not in test_indices]\n",
    "        \n",
    "        (X_train, y_train) = (X[train_indices,:], y[train_indices])\n",
    "        (X_test, y_test) = (X[test_indices,:], y[test_indices])\n",
    "\n",
    "        X_index_train = []\n",
    "        X_index_test = []\n",
    "\n",
    "        for i in train_indices:\n",
    "            X_index_train.append(X_index[i])\n",
    "\n",
    "        for i in test_indices:\n",
    "            X_index_test.append(X_index[i])\n",
    "        \n",
    "        clf = train(X_train, y_train, model)\n",
    "        \n",
    "        #test performance using X_test, y_test\n",
    "        fold_performance = evaluate(y_test, clf.predict(X_test))\n",
    "        print(\"Fold %d\"%(fold_no))\n",
    "        print(fold_performance)\n",
    "        \n",
    "        for key in fold_performance['keys']:\n",
    "            performance[key] +=fold_performance[key]\n",
    "        \n",
    "        #Show the samples with wrong predictions?\n",
    "    \n",
    "    for key in fold_performance['keys']:\n",
    "            performance[key]  = performance[key]/k\n",
    "    \n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "responsible-curve",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split():\n",
    "    (X, y, X_index) = load_dataset(DATA_DIR)\n",
    "    N = X.shape[0]\n",
    "    N_train = (int)(N*TRAIN_TEST_SPLIT[0])\n",
    "    N_test = N - N_train\n",
    "    \n",
    "    #print(N, N_train, N_test)\n",
    "    \n",
    "    test_indices = np.random.choice(N, N_test, replace=False)\n",
    "    train_indices = [i for i in range(0,N) if i not in test_indices]\n",
    "    \n",
    "    (X_train, y_train) = (X[train_indices,:], y[train_indices])\n",
    "    (X_test, y_test) = (X[test_indices,:], y[test_indices])\n",
    "    \n",
    "    X_index_train = []\n",
    "    X_index_test = []\n",
    "    \n",
    "    for i in train_indices:\n",
    "        X_index_train.append(X_index[i])\n",
    "        \n",
    "    for i in test_indices:\n",
    "        X_index_test.append(X_index[i])\n",
    "    \n",
    "    return (X_train, y_train, X_index_train, X_test, y_test, X_index_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "crucial-omaha",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "exotic-morocco",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_dev_split():\n",
    "    (X, y, X_index) = load_dataset(DATA_DIR)\n",
    "    N = X.shape[0]\n",
    "    N_train = (int)(N*TRAIN_TEST_DEV_SPLIT[0])\n",
    "    N_test = (int)(N*TRAIN_TEST_DEV_SPLIT[1])\n",
    "    N_dev = N - N_train - N_test\n",
    "    \n",
    "    print(N_train, N_test, N_dev)\n",
    "    \n",
    "    test_dev_indices = np.random.choice(N, (N_test+N_dev), replace=False)\n",
    "    \n",
    "    test_indices = test_dev_indices[0:N_test]\n",
    "    dev_indices = test_dev_indices[N_test:]\n",
    "    train_indices = [i for i in range(0,N) if i not in test_dev_indices]\n",
    "    \n",
    "    (X_train, y_train) = (X[train_indices,:], y[train_indices])\n",
    "    (X_test, y_test) = (X[test_indices,:], y[test_indices])\n",
    "    (X_dev, y_dev) = (X[dev_indices,:], y[dev_indices])\n",
    "    \n",
    "    X_index_train = []\n",
    "    X_index_test = []\n",
    "    X_index_dev = []\n",
    "    \n",
    "    for i in train_indices:\n",
    "        X_index_train.append(X_index[i])\n",
    "        \n",
    "    for i in test_indices:\n",
    "        X_index_test.append(X_index[i])\n",
    "        \n",
    "    for i in dev_indices:\n",
    "        X_index_dev.append(X_index[i])\n",
    "    \n",
    "    return (X_train, y_train, X_index_train, X_test, y_test, X_index_test, X_dev, y_dev, X_index_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cathedral-reliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test_dev_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "raised-invite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded\n"
     ]
    }
   ],
   "source": [
    "(X, y, X_index) = load_dataset(DATA_DIR)\n",
    "assert(X.shape[0]==y.shape[0] and y.shape[0]==len(X_index))\n",
    "print(\"Dataset Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "prompt-category",
   "metadata": {},
   "outputs": [],
   "source": [
    "#With raw features and full dataset: 0.6556543837357052\n",
    "\n",
    "#train model using X_train, y_train\n",
    "model = sklearn.svm.SVC(C=100)\n",
    "model.probability = True\n",
    "#clf = train(X, y, model)\n",
    "model.fit(X, y)\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'E:/Wasif/PDMotorFeatureExtraction/deepmag_svm_fullfit_model.pkl'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "impossible-mississippi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n",
      "(762,)\n",
      "(762,)\n"
     ]
    }
   ],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "prediction = loaded_model.predict(X)\n",
    "prediction_prob = loaded_model.predict_proba(X)\n",
    "print(prediction_prob[0].shape)\n",
    "print(prediction.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "isolated-cooling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6771653543307087 0.7516127593792734\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "accuracy = accuracy_score(y,prediction)\n",
    "roc = roc_auc_score(y, prediction_prob[:,0].flatten())\n",
    "print(accuracy, roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-while",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
